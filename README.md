## Employee Attrition Project: AnÃ¡lise Preditiva e Data Pipeline

Este projeto, originado em uma dinÃ¢mica de AnÃ¡lise Preditiva de RH (Employee Attrition), evoluiu para uma Prova de Conceito (PoC) de Engenharia de Dados. O objetivo principal Ã© estabelecer uma infraestrutura de dados integrada e automatizada entre o Google Drive e um Banco de Dados SQL, servindo de blueprint para futuros projetos da Empresa JÃºnior.


## âš™ï¸ Arquitetura do Projeto (Data Pipeline)

O fluxo de trabalho do projeto Ã© estruturado em um pipeline que garante a ingestÃ£o, transformaÃ§Ã£o e destino dos dados (ETL simplificado):

| Fase | DescriÃ§Ã£o | Tecnologias Chave |
| :--- | :--- | :--- |
| **Source (Fonte)** | Arquivos de dados CSV hospedados no Google Drive. | Google Drive, `gspread` |
| **Transform** | O Notebook Jupyter executa a lÃ³gica de limpeza, padronizaÃ§Ã£o e cÃ¡lculo das **Taxas de Rotatividade (Attrition Rates)**. | Python, Pandas |
| **Load (Carga)** | Os resultados sÃ£o carregados em destinos estratÃ©gicos para consumo. | PostgreSQL (`SQLAlchemy`), Google Sheets |

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

Para rodar este projeto localmente, siga os passos abaixo para configurar o ambiente virtual e as dependÃªncias.

### 1. Criar o Ambiente Virtual

Abra o terminal na pasta raiz do projeto e crie o ambiente virtual:

```bash
python3 -m venv venv
````

### 2\. Ativar o Ambiente

| Sistema Operacional | Comando |
| :--- | :--- |
| **Linux / macOS** | `source venv/bin/activate` |
| **Windows** | `venv\\Scripts\\activate` |

### 3\. Instalar as DependÃªncias

Com o ambiente ativado, instale todas as bibliotecas necessÃ¡rias:

```bash
venv/bin/pip install -r requirements.txt
```

## ğŸ” ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente

Este projeto utiliza variÃ¡veis de ambiente para gerenciar credenciais sensÃ­veis e URLs de conexÃ£o. Crie um arquivo chamado `.env` na **raiz** do projeto e preencha com suas configuraÃ§Ãµes:

```env
# ConfiguraÃ§Ãµes do Banco de Dados
DB_URL="postgresql://user:pass@localhost:5432/nome_do_seu_banco"

# ConfiguraÃ§Ãµes do Google Drive/Sheets
DRIVE_FOLDER_ID="o_id_da_sua_pasta_no_drive"
CREDS_PATH="./service_account_creds.json"
```

## ğŸ“ Estrutura do Projeto

A lÃ³gica de execuÃ§Ã£o reside primariamente na pasta `analysis/`.

```
.
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ .env                       # VariÃ¡veis de ambiente para o Notebook
â”‚   â”œâ”€â”€ credentials.json           # ğŸ‘ˆ Credenciais do Google Sheets/Drive
â”‚   â””â”€â”€ notebooks.ipynb            # ğŸ‘ˆ O Notebook principal de anÃ¡lise e execuÃ§Ã£o
â”œâ”€â”€ models/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ data_transform.py          # LÃ³gica de limpeza e transformaÃ§Ã£o de dados
â”‚   â””â”€â”€ main.py                    # FunÃ§Ãµes de utilidade (Ex: save_data_to_postgres)
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ google_drive_utils.py      # FunÃ§Ãµes de upload para o Drive/Sheets
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt
```

## ğŸ’» Como Executar a AnÃ¡lise

1.  Certifique-se de que o ambiente virtual estÃ¡ ativado.
2.  Inicie o Jupyter Notebook (ou JupyterLab):
    ```bash
    jupyter notebook
    ```
3.  Abra o arquivo `analysis/analysis.ipynb`.
4.  **Execute as cÃ©lulas em ordem.** O notebook irÃ¡:
      * Carregar as variÃ¡veis `.env`.
      * Aplicar transformaÃ§Ãµes nos dados (`pandas`).
      * Calcular todas as taxas de rotatividade necessÃ¡rias para o Dashboard.
      * **Salvar os DataFrames de resumo** no Google Sheets e no PostgreSQL.

Ao final, seu banco de dados estarÃ¡ alimentado com as tabelas de resumo para que vocÃª possa conectar o Power BI.

-----

*Desenvolvido com o intuito de aplicar conceitos de Data Engineering em uma anÃ¡lise de Data Science clÃ¡ssica.*
"""

